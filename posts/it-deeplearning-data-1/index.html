<!DOCTYPE html><html lang="ko-KR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="prefer-datetime-locale" content="ko"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="딥러닝 모델에게 데이터 떠먹이는 방법 (1)" /><meta name="author" content="dapin1490" /><meta property="og:locale" content="ko_KR" /><meta name="description" content="우리는 이걸 데이터 전처리라고 부르기로 했어요." /><meta property="og:description" content="우리는 이걸 데이터 전처리라고 부르기로 했어요." /><link rel="canonical" href="https://dapin1490.github.io/satinbower-legacy/posts/it-deeplearning-data-1/" /><meta property="og:url" content="https://dapin1490.github.io/satinbower-legacy/posts/it-deeplearning-data-1/" /><meta property="og:site_name" content="새틴바우어" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-02-28T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="딥러닝 모델에게 데이터 떠먹이는 방법 (1)" /><meta name="twitter:site" content="@dapin1490" /><meta name="twitter:creator" content="@dapin1490" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"dapin1490"},"dateModified":"2022-02-28T00:00:00+09:00","datePublished":"2022-02-28T00:00:00+09:00","description":"우리는 이걸 데이터 전처리라고 부르기로 했어요.","headline":"딥러닝 모델에게 데이터 떠먹이는 방법 (1)","mainEntityOfPage":{"@type":"WebPage","@id":"https://dapin1490.github.io/satinbower-legacy/posts/it-deeplearning-data-1/"},"url":"https://dapin1490.github.io/satinbower-legacy/posts/it-deeplearning-data-1/"}</script><title>딥러닝 모델에게 데이터 떠먹이는 방법 (1) | 새틴바우어</title><link rel="apple-touch-icon" sizes="180x180" href="/satinbower-legacy/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/satinbower-legacy/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/satinbower-legacy/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/satinbower-legacy/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/satinbower-legacy/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="새틴바우어"><meta name="application-name" content="새틴바우어"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/satinbower-legacy/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/satinbower-legacy/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/satinbower-legacy/" class="mx-auto"> <img src="/satinbower-legacy/assets/img/profile_image.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/satinbower-legacy/">새틴바우어</a></div><div class="site-subtitle font-italic">dapin1490's hand-made study blog</div></div><ul class="w-100"><li class="nav-item"> <a href="/satinbower-legacy/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>홈</span> </a><li class="nav-item"> <a href="/satinbower-legacy/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>카테고리</span> </a><li class="nav-item"> <a href="/satinbower-legacy/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>태그</span> </a><li class="nav-item"> <a href="/satinbower-legacy/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>아카이브</span> </a><li class="nav-item"> <a href="/satinbower-legacy/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>정보</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/dapin1490" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/dapin1490" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['dapin1490','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/satinbower-legacy/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/satinbower-legacy/"> 홈 </a> </span> <span>딥러닝 모델에게 데이터 떠먹이는 방법 (1)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 포스트</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="검색..."> </span> <span id="search-cancel" >취소</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4 pb-5"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>딥러닝 모델에게 데이터 떠먹이는 방법 (1)</h1><div class="post-meta text-muted"> <span> 게시 <em class="" data-ts="1645974000" data-df="YYYY-MM-DD" data-toggle="tooltip" data-placement="bottom"> 2022-02-28 </em> </span><div class="d-flex justify-content-between"> <span> By <em> dapin1490 </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3855 단어"> <em>21 분</em>읽는 시간</span></div></div></div><div class="post-content"><h3 id="우리는-이걸-데이터-전처리라고-부르기로-했어요"><span class="mr-2">우리는 이걸 데이터 전처리라고 부르기로 했어요.</span><a href="#우리는-이걸-데이터-전처리라고-부르기로-했어요" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><hr /><p><br /></p><h3 id="이-글의-목적"><span class="mr-2">이 글의 목적</span><a href="#이-글의-목적" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>캐글에서 유리 종류 구분하는 모델 만들면서 공부했던 것들을 여기에 정리해보겠다. 데이터를 어떻게든 다듬어서 정확도를 올려보겠다고 별 걸 다 공부했는데 그건 다 효과가 없었고 속성 몇 개 지웠더니 정확도가 20%p나 올라버려서 허무했지. <br /> 전체 코드 보기 : <a href="https://www.kaggle.com/dapin1490/glass/notebook">https://www.kaggle.com/dapin1490/glass/notebook</a> <br /> <a href="https://dapin1490.notion.site/DIY-ae97a364485946ae832f52e8022bf202">노션에도 정리해 두었으니 많이들 봐주시라구요</a> <br /> 참고 : 내가 이해한 대로 설명하는 것이니 틀린 부분이 있을 수 있다. 지적 환영!</p><p><br /><br /></p><h3 id="이번-글-목차"><span class="mr-2">이번 글 목차</span><a href="#이번-글-목차" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>1. 첨도와 왜도, 상관 관계<br /> 2. K겹 교차검증은 원 핫 벡터를 인자로 전달할 수 없다</p><p><br /><br /></p><h3 id="다음-글-보기"><span class="mr-2">다음 글 보기</span><a href="#다음-글-보기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="https://dapin1490.github.io/satinbower/posts/it-deeplearning-data-2/">딥러닝 모델에게 데이터 떠먹이는 방법 (2)</a></p><ul><li>데이터의 상태가 이상하다!<li>랜덤 언더, 오버 샘플링<li>SMOTE 오버 샘플링<li>ADASYN 오버 샘플링</ul><p><a href="https://dapin1490.github.io/satinbower/posts/it-deeplearning-data-3/">딥러닝 모델에게 데이터 떠먹이는 방법 (3)</a></p><ul><li>클래스 별 차등 가중치 부여하기<li>꼭 결측치가 있어야만 속성을 삭제할 수 있는 건 아니다</ul><p><br /></p><hr /><p><br /></p><h3 id="1-첨도와-왜도-상관-관계"><span class="mr-2">1. 첨도와 왜도, 상관 관계</span><a href="#1-첨도와-왜도-상관-관계" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><strong>- 필요 라이브러리</strong></p><div class="language-py highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="복사되었습니다!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
</pre></table></code></div></div><p><strong>- 첨도 : 데이터가 얼마나 한 지점에 몰려 있나?</strong> 를 나타낸다. 이 값이 클수록 데이터가 많이 몰려있다는 의미이고, 값이 작으면 데이터가 많이 퍼져있다는 뜻이다.</p><div class="language-py highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="복사되었습니다!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="c1"># 데이터셋의 속성 별 첨도 확인하기
</span><span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="nf">kurtosis</span><span class="p">())</span>


<span class="c1"># 속성 'K'의 히스토그램 보기
</span><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>  <span class="c1"># 그래프 보기
</span><span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>  <span class="c1"># 그래프 보기
</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">K</span><span class="sh">'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></table></code></div></div><p>첨도가 54.7쯤 되면 아래와 같은 히스토그램을 볼 수 있다. 세로축의 Count는 값의 개수, 가로축의 K는 이 속성의 이름이다. 딱 봐도 대략 0.1과 0.7쯤에 거의 모든 값이 몰려 있는 것을 확인할 수 있다.</p><figure style="text-align:center"> <img data-src="/satinbower-legacy/assets/img/category-it/220228-1-kurt-k.png" data-proofer-ignore><figcaption>[이미지 1] 첨도가 약 54.7인 속성의 히스토그램</figcaption></figure><p><strong>- 왜도 : 데이터가 얼마나 한 쪽에 치우쳐 있나?</strong> 를 나타낸다. 이 값이 양수이면 왼쪽에 치우쳐 있고(= 오른쪽 꼬리가 길고), 음수이면 오른쪽에 치우쳐 있다(= 왼쪽 꼬리가 길다). 요약하자면 절댓값이 클수록 꼬리가 길다.</p><div class="language-py highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="복사되었습니다!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="c1"># 속성 별 왜도 확인하기
</span><span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="nf">skew</span><span class="p">())</span>
</pre></table></code></div></div><p>위에서 확인했던 첨도가 약 54.7인 속성 ‘K’의 왜도는 약 6.6이다. 양수이고, 오른쪽에 자잘한 값이 길게 늘어지는 것을 [이미지 1]에서 확인할 수 있다.</p><p><br /><br /></p><p><strong>- 첨도와 왜도는 뭐가 다르냐?</strong></p><p>얼핏 보면 첨도나 왜도나 같은 말을 하는 것처럼 보일 수 있다. 하지만 잘 생각해 보면 분명한 차이가 있다. 정규분포를 가지고 이해해보자. 참고용으로 가져온 아래 그래프에서 빨간 그래프와 파란 그래프만을 본다. 빨간 그래프는 평균이 0, 분산이 1인 표준 정규 분포 그래프이다. 파란 그래프는 평균은 같지만 분산이 더 작다. 이 두 그래프의 첨도와 왜도는 어떻게 다를까?</p><figure style="text-align:center"> <img data-src="/satinbower-legacy/assets/img/category-it/220228-2-normal-distribution.png" data-proofer-ignore><figcaption>[이미지 2] 정규 분포 그래프, 출처 위키백과</figcaption></figure><p>편의상 빨간 그래프를 A, 파란 그래프를 B라고 부르자. 첨도는 B가 더 크고, 왜도는 같다. 여기서 첨도와 왜도의 차이를 알 수 있다. 첨도는 값이 몰려 있는 지점이 어디든, 몰려 있기만 하면 무조건 커지는 값이다. 왜도는 값이 얼마나 몰려 있는지에 영향을 받을 수는 있지만 그게 가장 중요한 요인은 되지 못한다. 아무리 값이 한 지점에 몰린다 해도 좌우 대칭을 유지한다면 왜도는 영향을 받지 않는다. 왜도는 아까 괄호에 덧붙인 설명 그대로, 어느 쪽 꼬리가 더 긴지 나타내는 지표이다.</p><p><br /><br /></p><p><strong>- 상관 관계 : 난 증가할 건데 넌 어느 쪽으로 가니?</strong> 라는 질문으로 이해할 수 있겠다. -1과 1 사이의 값을 가지며, -1에 가까울수록 반비례, 1에 가까울수록 정비례 관계이다. 첨도나 왜도와는 달리 무조건 값이 크다고 나쁜 것도 아니고 작다고 꼭 좋은 것도 아니다. 다만 알 수 있는 것은 절댓값이 작을 수록 상관 관계가 적다는 것이다.</p><div class="language-py highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="복사되었습니다!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="c1"># 클래스를 포함한 모든 속성 간의 상관 관계 수치로 확인하기
</span><span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="nf">corr</span><span class="p">())</span>


<span class="c1"># 상관 관계 히트맵 보기
</span><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>  <span class="c1"># 그래프 보기
</span><span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>  <span class="c1"># 그래프 보기
</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="nf">corr</span><span class="p">(),</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">"</span><span class="s">YlGnBu</span><span class="sh">"</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></table></code></div></div><p>상관 관계는 숫자로 확인할 수도 있긴 하지만 히트맵으로 보면 훨씬 보기 좋다. 아래 히트맵은 상관 관계가 1에 가까울수록 진한 색을 띈다. Type가 클래스이니 맨아랫줄을 보거나 가장 오른쪽 줄을 보면 클래스와 다른 속성 간의 상관 관계를 알 수 있다. 클래스와 정비례 방향으로 상관 관계가 가장 높은 것은 속성 ‘Al’이고, 반비례 방향으로 상관 관계가 가장 높은 것은 속성 ‘Mg’이다. 어느 방향으로든 상관 관계가 가장 낮은 것은 속성 ‘Ca’이다.</p><figure style="text-align:center"> <img data-src="/satinbower-legacy/assets/img/category-it/220228-3-heatmap.png" data-proofer-ignore><figcaption>[이미지 3] 상관 관계 시각화(히트맵)</figcaption></figure><p><br /><br /></p><h3 id="2-k겹-교차검증은-원-핫-벡터를-인자로-전달할-수-없다"><span class="mr-2">2. K겹 교차검증은 원 핫 벡터를 인자로 전달할 수 없다</span><a href="#2-k겹-교차검증은-원-핫-벡터를-인자로-전달할-수-없다" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><strong>- K겹 교차검증 : 이번엔 내가 테스트 데이터 할게 다음엔 네가 테스트 데이터 해</strong> <br /> 딥러닝 모델을 훈련시키고 그 성과를 확인하려면 테스트를 시켜야 한다. 보통은 전체 데이터셋에서 테스트 데이터를 따로 분할해 놓고 쓰거나, 모델을 실행할 때 validation_split 인자를 주어 학습 과정에서 알아서 나누어 쓰도록 한다(두 가지 방법을 한 번에 사용하기도 한다). 그런데 세상이 아무리 정보가 넘쳐나는 세상이 되었다고 한들 학습에 필요한 데이터가 부족한 문제는 얼마든지 있을 수 있다. K겹 교차검증은 이럴 때 사용할 수 있다. 그림부터 보고 이해하자.</p><figure style="text-align:center"> <img data-src="/satinbower-legacy/assets/img/category-it/220228-4-k-fold.png" data-proofer-ignore><figcaption>[이미지 4] K겹 교차검증, 출처 &lt;모두의 딥러닝&gt;</figcaption></figure><p>먼저 데이터셋을 프로그래머가 정한 개수(K개)로 나눈다. 그리고 그 중 하나씩을 테스트 데이터로 사용하며 총 K회 모델을 훈련시킨다. 각각의 테스트 결과로 나온 정확도를 평균내서 모델의 성능을 평가하는 방법이다. 모델을 아주 잘못 만든 게 아닌 이상 보통은 개별 결과가 서로 크게 차이나지 않는다.</p><p><strong>- K겹 교차검증 코드 보기</strong> : 코드 자체는 좀 간략하게 줄이려고 했는데 주석이 많아서 길어 보인다.</p><div class="language-py highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="복사되었습니다!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre><td class="rouge-code"><pre><span class="c1"># 라이브러리 불러오기
</span><span class="kn">from</span> <span class="n">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>  <span class="c1"># 모델 선언, 구조 결정
</span><span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>  <span class="c1"># 모델에 층 추가
</span><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>  <span class="c1"># K겹 교차검증
</span>
<span class="c1"># 교차검증 셋 분할
</span><span class="n">n_fold</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># 2개로 분할
# 분할 수는 최소 2개 이상 설정해야 한다.
# 1개로 설정할 거면 교차검증의 의미가 없으며, 오류가 난다.
# 난 그냥 모델 여러 번 실행해서 정확도 보기가 귀찮아서 이 방법을 쓴 거라 1로 해도 되는지 실행해봤다..
</span><span class="n">skf</span> <span class="o">=</span> <span class="nc">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_fold</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
<span class="c1"># n_splits=n_fold : 데이터를 몇 개로 나눌 것인지 정함
# shuffle=True : 데이터를 섞어서 분할
# random_state=seed : 랜덤 시드 설정
</span>
<span class="c1"># 빈 accuracy 배열 : K개의 테스트 정확도를 저장함
</span><span class="n">acc</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># my model
</span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">skf</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="nc">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">softmax</span><span class="sh">"</span><span class="p">))</span>
    
    <span class="c1"># model compile
</span>    <span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">"</span><span class="s">categorical_crossentropy</span><span class="sh">"</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="sh">"</span><span class="s">adam</span><span class="sh">"</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># validation_split=0.3 : 안 써도 된다. 학습 데이터 중 30%를 학습 중 모델의 테스트용으로 쓴다는 뜻이다.
</span>    
    <span class="n">k_acc</span> <span class="o">=</span> <span class="sh">"</span><span class="s">%.4f</span><span class="sh">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">test</span><span class="p">])[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">acc</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">k_acc</span><span class="p">)</span>


<span class="c1"># 결과 출력
# 주의 사항 : 일반적인 리스트가 아니기 때문에 mean()은 사용 불가하다.
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s"> %.f fold accuracy:</span><span class="sh">"</span> <span class="o">%</span> <span class="n">n_fold</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
</pre></table></code></div></div><p><strong>- 원 핫 인코딩, 원 핫 벡터 : 다른 건 보지 마 이게 정답이야 이것만 봐 좀</strong> <br /> 원 핫 인코딩은 예측해야 할 클래스가 선형 회귀가 아니고, 여러 개일 때 사용할 수 있는 방법이다. 예를 들어 0번부터 3번까지 클래스가 3개 있다고 하자. 프로그래머는 딥러닝 모델에게 이 클래스를 그대로 [0, 1, 2, 3]라고 전달할 수 있다. 그러나 보통은 원 핫 인코딩을 거쳐 [ [1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1] ] 이런 형태로 전달한다. 이렇게 정답 클래스의 인덱스만 1로 표시하고 나머지는 0으로 표시하는 것이 원 핫 인코딩이다. 그리고 원 핫 인코딩을 한 클래스 각각을 원 핫 벡터라고 한다.</p><p><strong>- 원 핫 벡터의 길이 : 누가 여기서 가장 크냐?</strong> <br /> 방금 예시에서는 클래스가 0부터 3까지 있었다. 그럼 만약 클래스가 1과 3만 있는 데이터를 원 핫 인코딩 한다면 어떻게 될까? 사람 기준에서는 어차피 둘 중 하나이니 [ [1, 0], [0, 1] ] 이렇게만 만들면 될 것 같지만 실제로 원 핫 인코딩을 해보면 위의 예시와 똑같은 결과가 나온다. 이유는 원 핫 인코딩이 표시하는 것이 클래스의 상대적 순서가 아니라, 인덱스 자체이기 때문이다. 파이썬의 인덱스는 0부터 시작하니, 정수로 표시된 클래스들 중 가장 큰 수를 받은 클래스의 숫자 + 1이 원 핫 벡터의 길이가 되고, 동시에 그것이 출력층의 노드 개수가 된다(클래스의 인덱스를 음수로 주는 경우는 본 적이 없다). 이는 자연어 처리에서도 똑같이 적용된다만, 지금 정리할 개념은 아니니 언급만 해둔다.</p><p><strong>- 원 핫 인코딩 왜 함?</strong> <br /> 원 핫 벡터에 사용되는 숫자와 클래스에 매겨지는 인덱스에 사용되는 숫자를 생각해 보자. 클래스 인덱스는 10진수로 매겨진다. 원 핫 벡터는 0과 1만 사용하니 2진수라고 할 수 있겠다. 10진수와 2진수의 차이가 뭘까? 10진수는 산수가 되고 2진수는 안 된다는 점이다. 10진수인 1과 2를 더하면 3이 되지만 원 핫 벡터는 모든 값을 0과 1로만 표시하면서 그런 계산을 불가능하게 만들었다. 이 부분이 원 핫 인코딩의 장점이자 단점이다.</p><p>사람은 데이터의 의미를 이해할 수 있으니 1번 클래스와 2번 클래스를 더하는 것과 3번 클래스는 무관하다는 사실을 인지할 수 있다. 하지만 모델은 그런 생각을 할 수 없다. 그렇기 때문에 클래스의 인덱스를 10진수로 주면 1 + 2 = 3이니까 1번 클래스와 2번 클래스를 더하면 3번 클래스와 같을 거라는 잘못된 학습을 할 수도 있다. 원 핫 인코딩은 이 문제를 방지한다. 이것이 장점이다.</p><p>반면 실제로 1번 클래스와 2번 클래스의 합이 3번 클래스와 관계가 있는 데이터도 있을 수 있다. 예를 들면 자연어 처리가 그러하다. 하나의 문장 내에서 각각의 단어는 무관하지 않다. “오늘 날씨”와 “내일 날씨”는 같은 “날씨”를 요구한다고 해도 다르게 해석되어야 한다. 원 핫 인코딩은 이런 관계성을 차단하여 클래스 사이의 유사성도 나타내지 못하게 된다는 것이 단점이다.</p><p><strong>- K겹 교차검증에 원 핫 인코딩을 못쓴다고?</strong> <br /> K겹 교차검증은 데이터 전체를 우선 K개의 세트로 분할한 후 모델에 주어 학습시킨다. 이때 클래스는 원 핫 벡터 형태로 넘겨줄 수 없다. 이유까지 아는 것은 아니고, 오류가 떠서 알게 된 사실이다.</p><p>그렇다면 K겹 교차검증을 하려거든 원 핫 인코딩을 포기해야 할까? 다행히도 그렇지는 않다. 데이터셋을 먼저 분할하여 반복문 내에 진입한 후, 그 안에서 원 핫 인코딩을 실행하면 된다. 그게 다다!</p><p><strong>- K겹 교차검증과 원 핫 인코딩</strong> : 이제와서 밝히지만 위의 K겹 교차검증 코드는 이 코드에서 원 핫 인코딩 부분만 지운 것이라 그대로 실행하면 오류가 발생할 수 있다. 그건 참고로만 보자. 이 코드는 실행 가능하다.</p><div class="language-py highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="복사되었습니다!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre><td class="rouge-code"><pre><span class="c1"># make model
</span><span class="kn">from</span> <span class="n">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>  <span class="c1"># 모델 선언, 구조 결정
</span><span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>  <span class="c1"># 모델에 층 추가
</span><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>  <span class="c1"># K겹 교차검증
</span>
<span class="c1"># 교차검증 셋 분할
</span><span class="n">n_fold</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">skf</span> <span class="o">=</span> <span class="nc">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_fold</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># 빈 accuracy 배열
</span><span class="n">acc</span> <span class="o">=</span> <span class="p">[]</span>

<span class="kn">from</span> <span class="n">keras.utils</span> <span class="kn">import</span> <span class="n">np_utils</span>  <span class="c1"># 원 핫 인코딩
</span>
<span class="c1"># my model
</span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">skf</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="c1"># 분할되어 들어온 클래스 데이터를 원 핫 인코딩 한다.
</span>    <span class="n">Y_one_tr</span> <span class="o">=</span> <span class="n">np_utils</span><span class="p">.</span><span class="nf">to_categorical</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
    <span class="n">Y_one_te</span> <span class="o">=</span> <span class="n">np_utils</span><span class="p">.</span><span class="nf">to_categorical</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">test</span><span class="p">])</span>
    
    <span class="c1"># 이후는 전과 같다.
</span>    <span class="n">model</span> <span class="o">=</span> <span class="nc">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">softmax</span><span class="sh">"</span><span class="p">))</span>
    
    <span class="c1"># model compile
</span>    <span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">"</span><span class="s">categorical_crossentropy</span><span class="sh">"</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="sh">"</span><span class="s">adam</span><span class="sh">"</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">Y_one_tr</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">k_acc</span> <span class="o">=</span> <span class="sh">"</span><span class="s">%.4f</span><span class="sh">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">Y_one_te</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">acc</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">k_acc</span><span class="p">)</span>


<span class="c1"># 결과 출력
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s"> %.f fold accuracy:</span><span class="sh">"</span> <span class="o">%</span> <span class="n">n_fold</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
</pre></table></code></div></div></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/satinbower-legacy/categories/it/'>IT</a>, <a href='/satinbower-legacy/categories/machine-learning/'>Machine Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/satinbower-legacy/tags/%EC%A7%80%EC%8B%9D/" class="post-tag no-text-decoration" >지식</a> <a href="/satinbower-legacy/tags/it/" class="post-tag no-text-decoration" >IT</a> <a href="/satinbower-legacy/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/" class="post-tag no-text-decoration" >딥러닝</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 이 기사는 저작권자의 <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.ko"> CC BY-NC-ND 4.0 </a> 라이센스를 따릅니다.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">공유하기</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=%EB%94%A5%EB%9F%AC%EB%8B%9D+%EB%AA%A8%EB%8D%B8%EC%97%90%EA%B2%8C+%EB%8D%B0%EC%9D%B4%ED%84%B0+%EB%96%A0%EB%A8%B9%EC%9D%B4%EB%8A%94+%EB%B0%A9%EB%B2%95+%281%29+-+%EC%83%88%ED%8B%B4%EB%B0%94%EC%9A%B0%EC%96%B4&url=https%3A%2F%2Fdapin1490.github.io%2Fsatinbower-legacy%2Fposts%2Fit-deeplearning-data-1%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="링크 복사하기" data-title-succeed="링크가 복사되었습니다!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">최근 업데이트</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/satinbower-legacy/posts/backend-internet-230704/">[Backend] 인터넷이 뭔데</a><li><a href="/satinbower-legacy/posts/it-boj-1254/">[python] 백준 1254 팰린드롬 만들기</a><li><a href="/satinbower-legacy/posts/py-exe-release/">[python] GUI 프로그램 exe 만들고 배포하기, 소멸자와 로깅</a><li><a href="/satinbower-legacy/posts/daily-230617/">23년 1학기 14주 수업</a><li><a href="/satinbower-legacy/posts/chatgpt-230103/">Unity vs Unreal Engine</a></ul></div><div id="access-tags"><div class="panel-heading">인기 태그</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/satinbower-legacy/tags/%EC%A7%80%EC%8B%9D/">지식</a> <a class="post-tag" href="/satinbower-legacy/tags/it/">IT</a> <a class="post-tag" href="/satinbower-legacy/tags/%EB%82%B4%EA%B0%80-%ED%95%B4%EB%83%84/">내가 해냄</a> <a class="post-tag" href="/satinbower-legacy/tags/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0/">자료구조</a> <a class="post-tag" href="/satinbower-legacy/tags/%EB%AC%B8%EC%A0%9C%ED%92%80%EC%9D%B4/">문제풀이</a> <a class="post-tag" href="/satinbower-legacy/tags/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a> <a class="post-tag" href="/satinbower-legacy/tags/%EA%B3%BC%EC%A0%9C/">과제</a> <a class="post-tag" href="/satinbower-legacy/tags/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/">프로젝트</a> <a class="post-tag" href="/satinbower-legacy/tags/leetcode/">LeetCode</a> <a class="post-tag" href="/satinbower-legacy/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">바로가기</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>관련된 글</h3><div class="card-deck mb-4"><div class="card"> <a href="/satinbower-legacy/posts/it-deep-learning/"><div class="card-body"> <em class="small" data-ts="1637506800" data-df="YYYY-MM-DD" > 2021-11-22 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>딥러닝의 탄생과 활용</h3><div class="text-muted small"><p> 게임과 인공지능 * 대학 과제로 작성된 글이며, IT 계열 전공 1학년생 수준으로 쓰였음을 알림. 목차 1. 서론 2-1. 인공지능 2-2. 딥러닝 3. 게임과 인공지능 1. 서론 코로나19의 영향으로 비대면 콘텐츠가 나날이 늘어나고 있는 요즘, 많은 이들이 한 번쯤 게임을 즐겨본 적이 있을 것이다. 게임은 RPG, 액션, 퍼즐 ...</p></div></div></a></div><div class="card"> <a href="/satinbower-legacy/posts/it-deeplearning-data-2/"><div class="card-body"> <em class="small" data-ts="1646406000" data-df="YYYY-MM-DD" > 2022-03-05 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>딥러닝 모델에게 데이터 떠먹이는 방법 (2)</h3><div class="text-muted small"><p> 우리는 이걸 데이터 전처리라고 부르기로 했어요. 참고 사용한 데이터셋 : https://www.kaggle.com/uciml/glass 내 코드 보기 : https://www.kaggle.com/dapin1490/glass/notebook 노션에서 정리 보기 : https://dapin1490.notion.site/DIY-ae97a3644...</p></div></div></a></div><div class="card"> <a href="/satinbower-legacy/posts/it-deeplearning-data-3/"><div class="card-body"> <em class="small" data-ts="1646406060" data-df="YYYY-MM-DD" > 2022-03-05 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>딥러닝 모델에게 데이터 떠먹이는 방법 (3)</h3><div class="text-muted small"><p> 우리는 이걸 데이터 전처리라고 부르기로 했어요. 참고 사용한 데이터셋 : https://www.kaggle.com/uciml/glass 내 코드 보기 : https://www.kaggle.com/dapin1490/glass/notebook 노션에서 정리 보기 : https://dapin1490.notion.site/DIY-ae97a3644...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/satinbower-legacy/posts/it-quick-sort/" class="btn btn-outline-primary" prompt="이전 글"><p>퀵 정렬</p></a> <a href="/satinbower-legacy/posts/it-deeplearning-data-2/" class="btn btn-outline-primary" prompt="다음 글"><p>딥러닝 모델에게 데이터 떠먹이는 방법 (2)</p></a></div></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/dapin1490">dapin1490</a>. <span data-toggle="tooltip" data-placement="top" title="명시되지 않는 한 이 사이트의 블로그 게시물은 작성자의 Creative Commons Attribution 4.0 International(CC BY-NC-ND 4.0) 라이선스에 따라 사용이 허가되었습니다.">일부 권리 보유</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">인기 태그</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/satinbower-legacy/tags/%EC%A7%80%EC%8B%9D/">지식</a> <a class="post-tag" href="/satinbower-legacy/tags/it/">IT</a> <a class="post-tag" href="/satinbower-legacy/tags/%EB%82%B4%EA%B0%80-%ED%95%B4%EB%83%84/">내가 해냄</a> <a class="post-tag" href="/satinbower-legacy/tags/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0/">자료구조</a> <a class="post-tag" href="/satinbower-legacy/tags/%EB%AC%B8%EC%A0%9C%ED%92%80%EC%9D%B4/">문제풀이</a> <a class="post-tag" href="/satinbower-legacy/tags/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a> <a class="post-tag" href="/satinbower-legacy/tags/%EA%B3%BC%EC%A0%9C/">과제</a> <a class="post-tag" href="/satinbower-legacy/tags/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/">프로젝트</a> <a class="post-tag" href="/satinbower-legacy/tags/leetcode/">LeetCode</a> <a class="post-tag" href="/satinbower-legacy/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">새 버전의 콘텐츠를 사용할 수 있습니다.</p><button type="button" class="btn btn-primary" aria-label="Update"> 업데이트 </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/satinbower-legacy/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">검색 결과가 없습니다.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/ko.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/satinbower-legacy/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/satinbower-legacy/app.js"></script>
